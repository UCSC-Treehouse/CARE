{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "Generate Threshold files\n",
    "March 1, 2017\n",
    "\n",
    "Based on : MakeThresholdsAndExprVarFilteredList-pancan-and-pandisease.v3.ipynb\n",
    "\n",
    "create PanCancer & PanDisease threshold files for a single sample using the cohort samples list\n",
    "generated in steps 2.0 and 2.2.\n",
    "\n",
    "Also creates: self-disease, first-degree MCS, and first-and-second-degree MCS thresholds.\n",
    "\n",
    "If any threshold list can't be created, it will be set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import logging\n",
    "import errno\n",
    "\n",
    "# Setup: load conf, retrieve sample ID, logging\n",
    "with open(\"conf.json\",\"r\") as conf:\n",
    "    c=json.load(conf)\n",
    "sample_id = c[\"sample_id\"]    \n",
    "print(\"Running on sample: {}\".format(sample_id))\n",
    "\n",
    "logging.basicConfig(**c[\"info\"][\"logging_config\"])\n",
    "logging.info(\"\\n3: Generate Threshold Files\")\n",
    "def and_log(s):\n",
    "    logging.info(s)\n",
    "    return s\n",
    "\n",
    "# if the analysis failed, create (if necessary) the flag file and\n",
    "# add to it the reason it failed; increase max fail level if necessary\n",
    "def mark_analysis_failed(text, level):\n",
    "    try:\n",
    "        with open(c[\"file\"][\"flag_analysis_failed\"], \"r\") as jf:\n",
    "            failed_json = json.load(jf)\n",
    "    except IOError, e:\n",
    "        if e.errno == errno.ENOENT:\n",
    "            failed_json = {\"reason\": {}, \"maxlevel\": str(level)}\n",
    "        else:\n",
    "            raise\n",
    "    if int(failed_json[\"maxlevel\"]) < level:\n",
    "        failed_json[\"maxlevel\"] = str(level)\n",
    "    if \"3\" in failed_json[\"reason\"].keys():\n",
    "        failed_json[\"reason\"][\"3\"] = failed_json[\"reason\"][\"3\"] + text\n",
    "    else:\n",
    "        failed_json[\"reason\"][\"3\"] = text\n",
    "    with open(c[\"file\"][\"flag_analysis_failed\"], \"w\") as jf:\n",
    "        json.dump(failed_json, jf, indent=2)\n",
    "\n",
    "#### Configuration ####\n",
    "\n",
    "iqr_multiplier=c[\"info\"][\"iqr_multiplier\"]\n",
    "# What % of a feature need have 0 expression for it to be dropped?\n",
    "proportion_unexpressed = c[\"info\"][\"proportion_unexpressed_filter_cutoff\"]\n",
    "# Drop this proportion of the lowest-varying genes\n",
    "filter_level = c[\"info\"][\"variance_filter_cutoff\"]\n",
    "\n",
    "# IMPORTANT\n",
    "# What number is considered zero for the purposes of the \"0 expression\" cutoff?\n",
    "# This - or anything below - will count as 0.\n",
    "# See https://github.com/UCSC-Treehouse/operations/issues/25#issuecomment-268610013\n",
    "#zero_threshold = 0.0001443\n",
    "zero_threshold = np.float64(c[\"info\"][\"cohort_zero_threshold\"])\n",
    "print(\"Threshold Zero Value for this cohort:{}\".format(zero_threshold))\n",
    "\n",
    "# Input requires steps: 2.0, 2.2\n",
    "with open(c[\"json\"][\"2.0\"],\"r\") as jf:\n",
    "        json_2pt0 = json.load(jf)\n",
    "        \n",
    "with open(c[\"json\"][\"2.2\"],\"r\") as jf:\n",
    "        json_2pt2 = json.load(jf)\n",
    "        \n",
    "# Output json\n",
    "j = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# Takes : pandas dataframe, float iqr_multiplier\n",
    "# returns a pandas dataframe - columns high, median, low\n",
    "def make_thresholds(dataframe, iqr_mult):\n",
    "    \n",
    "    # Calculate the thresholds at 25%, 50%, and 100%\n",
    "    thresholds = dataframe.quantile(q=[0.25, 0.5, 0.75], axis=1)\n",
    "    # add the IQR - subtract 25% quantile from 75% quantile\n",
    "    thresholds.loc[\"IQR\"] = thresholds.loc[0.75] - thresholds.loc[0.25]\n",
    "\n",
    "    # Then, make high, median and low thresholds\n",
    "    high_threshold = thresholds.loc[0.75] + (iqr_mult * thresholds.loc[\"IQR\"])\n",
    "    low_threshold = thresholds.loc[0.25] - (iqr_mult * thresholds.loc[\"IQR\"])\n",
    "    median = thresholds.loc[0.50] \n",
    "    return pd.concat({ \"high\": high_threshold, \"median\": median, \"low\": low_threshold}, axis=1)\n",
    "\n",
    "# Takes : dataframe, float proportion unexpressed, float filter level\n",
    "# float zero_threshold -- anything <= to this value is considered zero\n",
    "# returns pandas dataframe where the index are the genes to KEEP\n",
    "def make_expr_var_filters(dataframe, proportion_unexpressed, filter_level, zero_threshold):\n",
    "    \n",
    "    ### Expression Variance Filters\n",
    "\n",
    "    # unroll the count of zeroes\n",
    "    max_ok_zeroes = len(dataframe.columns) * proportion_unexpressed\n",
    "\n",
    "    # Is the count of items less than threshold within the acceptable count?\n",
    "    def sufficiently_expressed(series, max_zeroes,threshold):\n",
    "            return len(series[series <= threshold]) < max_zeroes\n",
    "\n",
    "    # Gene & whether it is Keep (True) or too many zeroes (False)    \n",
    "    withZeroes = dataframe.apply(sufficiently_expressed,\n",
    "                            args=(max_ok_zeroes, zero_threshold),\n",
    "                            axis=1)\n",
    "\n",
    "    # Next, do variance filtering\n",
    "    expression_filtered_compendium = dataframe[withZeroes]\n",
    "    print \"{} genes remain after expression filter\".format(\n",
    "        len(expression_filtered_compendium))\n",
    "\n",
    "    # Get the standard deviation\n",
    "    variance = expression_filtered_compendium.apply(np.std, axis=1)\n",
    "    cut_proportion = int(math.ceil(len(variance)*filter_level))\n",
    "    keep_proportion = len(variance) - cut_proportion\n",
    "    expression_and_variance_filtered = variance.nlargest(keep_proportion)\n",
    "    print \"{} genes remain after variance filter\".format(\n",
    "        len(expression_and_variance_filtered))\n",
    "    return expression_and_variance_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load the expression\n",
    "\n",
    "# If this fails with 'no module named tables', uncomment and rerun:\n",
    "#!pip2 install --quiet tables\n",
    "\n",
    "expression = pd.read_hdf(c[\"cohort\"][\"expression_hd5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Combine the sample lists from the 2.0 and 2.2 jsons.\n",
    "sample_lists ={\n",
    "    \"pancan\": json_2pt0[\"pancan_samples\"],\n",
    "    \"pandis\": json_2pt0[\"pandisease_samples\"],\n",
    "    \"first_degree\": json_2pt0[\"first_degree_mcs_cohort\"],\n",
    "    \"first_and_second_degree\": json_2pt2[\"first_and_second_degree_mcs_cohort\"],\n",
    "    \"nof1_disease\": json_2pt2[\"diagnosed_disease_cohort\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Filter the expression by the sample lists. Abort if there's any sample in the list\n",
    "# that isn't found in the expression - this shouldn't be allowed to ever happen\n",
    "\n",
    "# Drop cohorts with fewer than a threshold (currently 20) samples\n",
    "\n",
    "MINIMUM_DIAGNOSIS_COHORT_THRESHOLD = 20\n",
    "\n",
    "expression_lists = {}\n",
    "cohorts_without_samples = []\n",
    "for listname, samples in sample_lists.iteritems():\n",
    "    if(len(samples) < MINIMUM_DIAGNOSIS_COHORT_THRESHOLD):\n",
    "        print \"{} found {} samples (minimum is {}). Skipping this cohort.\".format(\n",
    "            listname,\n",
    "            len(samples),\n",
    "            MINIMUM_DIAGNOSIS_COHORT_THRESHOLD)\n",
    "        expression_lists[listname] = []\n",
    "        cohorts_without_samples.append(listname)\n",
    "    elif(len(expression.columns.intersection(samples)) != len(samples)):\n",
    "        print(\"Error! At least one sample from the {} list was not found in the expression table!\").format(listname)\n",
    "        raise KeyboardInterrupt\n",
    "    else:\n",
    "        expression_lists[listname] = expression.loc[:, samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Make some alerts / errors if any cohorts are missing samples.\n",
    "\n",
    "error_reasons = {\n",
    "    \"pancan\":(\"pancancer\", \"This should never happen!\"),\n",
    "    \"pandis\": (\"disease of top6 MCS above threshold\", \n",
    "               \"This is typically because there were too few samples that passed the \" +\n",
    "               \"95% similarity threshold.\"),\n",
    "    \"first_degree\": (\"first degree MCS\",\n",
    "                     \"This is typically because there were too few samples that passed the \" +\n",
    "                     \"95% similarity threshold.\"),\n",
    "    \"first_and_second_degree\": (\"first and second degree MCS\",\n",
    "                     \"This is typically because there were too few samples that passed the \" +\n",
    "                     \"95% similarity threshold.\"),\n",
    "    \"nof1_disease\": (\"focus sample's disease\", \"This is typically because there was no disease provided \" +\n",
    "                     \"or there were too few samples with the focus sample's disease\")\n",
    "}\n",
    "\n",
    "for cohort in cohorts_without_samples:\n",
    "    longname, explanation = error_reasons[cohort]\n",
    "    text = \"<br/>ERROR: There are no samples in the {} cohort ({}). {}\".format(longname, cohort, explanation)\n",
    "    if cohort == \"pancan\":\n",
    "        mark_analysis_failed(text, 4)\n",
    "    else:\n",
    "        mark_analysis_failed(text, 2)\n",
    "    print text\n",
    "\n",
    "if len(cohorts_without_samples) == 4:\n",
    "    text = (\"<br/>ERROR: In total, there were 4 cohorts with insufficent samples. There are no outliers \"\n",
    "        \"from personalized cohorts for this sample, although there may be pan-cancer outliers.\")\n",
    "    mark_analysis_failed(text, 4)\n",
    "    print text\n",
    "elif len(cohorts_without_samples) == 3:\n",
    "    text = (\"<br/>ERROR: In total, there were 3 cohorts with insufficent samples. No consensus outliers \"\n",
    "            \"are available, although there may be pan-cancer outliers. Outliers for the single \"\n",
    "            \"personalized cohort can be found in the outliers file but were not further analyzed. \")\n",
    "    mark_analysis_failed(text, 4)\n",
    "    print text\n",
    "elif len(cohorts_without_samples) == 2:\n",
    "    text = (\"<br/>ERROR: In total, there were 2 cohorts with insufficient samples.<br/>\"\n",
    "        \"Any outliers from the remaining cohorts are not consensus outliers, but are reported \"\n",
    "        \"in case a more weakly-supported finding is desired. Only consider  leads based on \"\n",
    "        \"these results if you thoroughly understand the weaknesses of the data and report the \"\n",
    "        \"weakness to the clinician.\")\n",
    "    mark_analysis_failed(text, 4)\n",
    "    print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Get the thresholds and filtered genes. Skip empty cohorts.\n",
    "thresholds = {}\n",
    "filters = {}\n",
    "for listname, expression_values in expression_lists.iteritems():\n",
    "    if(len(expression_values)):\n",
    "        thresholds[listname] = make_thresholds(expression_values, iqr_multiplier) \n",
    "        filters[listname] = make_expr_var_filters(\n",
    "            expression_values, proportion_unexpressed, filter_level, zero_threshold)   \n",
    "    else:\n",
    "        thresholds[listname] = []\n",
    "        filters[listname] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Format thresholds for output\n",
    "# pancan_thresholds, pandis_thresholds\n",
    "# first_degree_thresholds, first_and_second_degree_thresholds, nof1_disease_thresholds\n",
    "# pancan_filtered_genes, pandis_filtered_genes\n",
    "# first_degree_filtered_genes, first_and_second_degree_filtered_genes, nof1_disease_filtered_genes\n",
    "\n",
    "for listname in sample_lists.keys():\n",
    "    threshold_key = \"{}_thresholds\".format(listname)\n",
    "    filtered_key = \"{}_filtered_genes\".format(listname)\n",
    "    if(len(thresholds[listname])):\n",
    "        threshold_stringdata = thresholds[listname].applymap(lambda x: \"%.15g\" % x)\n",
    "        j[threshold_key] = json.loads(threshold_stringdata.to_json(orient='columns'))\n",
    "    else:\n",
    "        j[threshold_key] = {}\n",
    "    if(len(filters[listname])):\n",
    "        j[filtered_key] = filters[listname].index.values.tolist()\n",
    "    else:\n",
    "        j[filtered_key] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write output\n",
    "with open(c[\"json\"][\"3\"], \"w\") as jsonfile:\n",
    "    json.dump(j, jsonfile, indent=2)\n",
    "    \n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
