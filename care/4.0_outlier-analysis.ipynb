{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Outlier Analysis\n",
    "## Pan-Cancer and Personalized Cohorts\n",
    "\n",
    "This script runs outlier analysis on an n-of-1 sample against pre-generated thresholds.\n",
    "It returns two levels of results: pan-cancer and personalized.\n",
    "\n",
    "### Input \n",
    "- the sample log2(tpm+1) from step 1\n",
    "- the thresholds from each background cohort, from step 3\n",
    "\n",
    "### Output\n",
    "Two output files.\n",
    "#### outlier_results_SAMPLEID \n",
    "contains the following columns, in this order:\n",
    "\n",
    "- sample: in log2(tpm+1)\n",
    "- is_top_5 : blank or \"top5\"\n",
    "\n",
    "pancancer thresholds in log2(tpm+1):\n",
    "- pc_low  \n",
    "- pc_median\t\n",
    "- pc_high\n",
    "\n",
    "- pc_outlier: blank, \"pc_up\" or \"pc_down\"\n",
    "\n",
    "- pc_is_filtered : blank or \"pc_dropped\"\n",
    "\n",
    "pandisease thresholds in log2(tpm+1). Present to maintain continuity of file format,\n",
    "but will always be blank as the consensus outliers are no longer derivable from these thresholds.\n",
    "\n",
    "- pd_low\t\n",
    "- pd_median\t\n",
    "- pd_high\t\n",
    "\n",
    "The consensus outlier results based on combining our customized cohorts:\n",
    "- pd_outlier:  blank, \"pd_up\" or \"pd_down\"\n",
    "\n",
    "Pancancer percentile the sample's expression was for this gene:\n",
    "- pc_percentile\n",
    "\n",
    "\n",
    "\n",
    "#### 4.0.json \n",
    "contains the following keys:\n",
    "\n",
    "- 'outlier_results' jsonification of the above CSV\n",
    "- 'personalized_outliers' outliers for each personalized cohort individually listed\n",
    "- 'personalized_consensus_counts' : outliers appearing in 2 or more cohorts, with the count of how many cohorts.\n",
    "\n",
    "### Pan-cancer cohort:\n",
    " - Runs against the chosen background_cohort\n",
    " - results filtered against the expression-variance filters\n",
    " - up outliers filtered against top5% expression values\n",
    "\n",
    "### Personalized cohorts:\n",
    " - results are NOT filtered vs expression-variance\n",
    " - up outliers filtered against top5% expression values\n",
    " - personalized cohorts are :\n",
    "    - pandis\n",
    "    - first_degree\n",
    "    - first_and_second_degree\n",
    "    - nof1_disease\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import errno # for errno.EEXIST. specific to python 2.7.5. https://github.com/beautify-web/js-beautify/pull/349 \n",
    "import json\n",
    "import bisect\n",
    "import logging\n",
    "\n",
    "\n",
    "# Setup: load conf, retrieve sample ID, logging\n",
    "with open(\"conf.json\",\"r\") as conf:\n",
    "    c=json.load(conf)\n",
    "sample_id = c[\"sample_id\"]    \n",
    "print(\"Running on sample: {}\".format(sample_id))\n",
    "\n",
    "logging.basicConfig(**c[\"info\"][\"logging_config\"])\n",
    "logging.info(\"\\n4: Outlier Analysis\")\n",
    "def and_log(s):\n",
    "    logging.info(s)\n",
    "    return s\n",
    "\n",
    "# if the analysis failed, create (if necessary) the flag file and\n",
    "# add to it the reason it failed; increase max fail level if necessary\n",
    "def mark_analysis_failed(text, level):\n",
    "    try:\n",
    "        with open(c[\"file\"][\"flag_analysis_failed\"], \"r\") as jf:\n",
    "            failed_json = json.load(jf)\n",
    "    except IOError, e:\n",
    "        if e.errno == errno.ENOENT:\n",
    "            failed_json = {\"reason\": {}, \"maxlevel\": str(level)}\n",
    "        else:\n",
    "            raise\n",
    "    if int(failed_json[\"maxlevel\"]) < level:\n",
    "        failed_json[\"maxlevel\"] = str(level)\n",
    "    if \"4.0\" in failed_json[\"reason\"].keys():\n",
    "        failed_json[\"reason\"][\"4.0\"] = failed_json[\"reason\"][\"4.0\"] + text\n",
    "    else:\n",
    "        failed_json[\"reason\"][\"4.0\"] = text\n",
    "    with open(c[\"file\"][\"flag_analysis_failed\"], \"w\") as jf:\n",
    "        json.dump(failed_json, jf, indent=2)\n",
    "    \n",
    "# Input requires steps: 1, 3\n",
    "with open(c[\"json\"][\"1\"],\"r\") as jf:\n",
    "    expression=pd.DataFrame.from_dict(\n",
    "        json.load(jf)[\"tpm_hugo_norm_uniq\"],\n",
    "        orient=\"columns\",\n",
    "        dtype=\"float64\")\n",
    "with open(c[\"json\"][\"3\"],\"r\") as jf:\n",
    "        json_3 = json.load(jf)\n",
    "        \n",
    "j = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function for quantile expression. Used with pd.apply. takes a gene column\n",
    "# from the binned cohort, the entire sample data frame, and the sample id\n",
    "def get_sample_quantile(cohort_column, sample_df, sample_id):\n",
    "    sample_value = sample_df.loc[cohort_column.name][sample_id] # a single number\n",
    "    column_values = cohort_column.values # an array of the percentile values, 0 to 100\n",
    "    \n",
    "    leftmost = bisect.bisect_left(column_values, sample_value)\n",
    "    rightmost = bisect.bisect_right(column_values, sample_value)\n",
    "    \n",
    "    return int((float(leftmost) + float(rightmost) - 1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate the genes in the top 5% of the N-of-1 sample\n",
    "# takes sample expression as series\n",
    "def sample_top5percent_genes(sample_expression):\n",
    "    top5_value = sample_expression.describe(percentiles=[0.95]).loc[\"95%\"]    \n",
    "    top5_valuelists = sample_expression.loc[lambda x: x >= top5_value]\n",
    "    \n",
    "    # Exclude genes with zero expression from the top5%. If any such genes are present, \n",
    "    # the sample is considered QC fail - mark this by creating the ANALYSIS_FAILED file.\n",
    "    if(top5_value <= 0):\n",
    "        top5_valuelists = top5_valuelists.loc[lambda x: x > 0]\n",
    "        \n",
    "        qc_failure_text = (\"QC_FAIL_LowTop5GeneCount: Top 5% threshold is equal to or lower than 0.<br/>\"\n",
    "                          \"Fewer than five percent of the genes in this sample have expression greater than zero.\")\n",
    "        print(qc_failure_text)\n",
    "        logging.error(qc_failure_text)\n",
    "        mark_analysis_failed(qc_failure_text, 4)\n",
    "\n",
    "    return top5_valuelists.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the outlier analysis! Inputs:\n",
    "#\n",
    "# sample_expression: Series (not data frame) of the sample expression data\n",
    "#\n",
    "# Thresholds dict - dictionary suitable for loading into a data frame; created\n",
    "# from dataframe.to_json(orient='columns'). Contains columns for 'high', 'median',\n",
    "# and 'low' thresholds per gene.\n",
    "#\n",
    "# top5_genes - list of gene names for the N-of-1 sample's top 5% of expression\n",
    "#\n",
    "# is_filtered -- whether to apply a filter to the genes for up or down outliers\n",
    "#\n",
    "# filtered_genes -- an array of strings that are the names of the genes to KEEP;\n",
    "# ignored unless is_filtered\n",
    "\n",
    "\n",
    "def get_outliers(sample_expression,\n",
    "                  thresholds_dict,\n",
    "                  top5_genes,\n",
    "                  is_filtered=False,\n",
    "                  filtered_genes_array=[] \n",
    "                  ):\n",
    "        \n",
    "    expression_thresholds = pd.DataFrame.from_dict(thresholds_dict, orient=\"columns\", dtype=\"float32\")\n",
    "    \n",
    "    # Down outliers \n",
    "    down_outliers = sample_expression.loc[lambda x: x < expression_thresholds[\"low\"]]\n",
    "    down_with_median = pd.concat([expression_thresholds[\"median\"],down_outliers],axis=1,join=\"inner\" )\n",
    "    \n",
    "    # Up outliers - filter by top5% genes of the n-of-1 sample\n",
    "    up_outliers = sample_expression.loc[lambda x: x > expression_thresholds[\"high\"]]\n",
    "    up_with_median = pd.concat([expression_thresholds[\"median\"],up_outliers],axis=1,join=\"inner\" )\n",
    "    up_in_top5 = up_with_median.loc[top5_genes.intersection(up_with_median.index)]\n",
    "    \n",
    "    if(is_filtered):\n",
    "        print \"    Using expression variance filters\"\n",
    "        filteredgenes = pd.Index(data=filtered_genes_array, copy=False, name=\"Gene\")         \n",
    "        final_up=up_in_top5.loc[filteredgenes.intersection(up_in_top5.index)]\n",
    "        final_down=down_with_median.loc[filteredgenes.intersection(down_with_median.index)]\n",
    "    else:\n",
    "        print \"    Not using expression variance filters\"\n",
    "        filteredgenes = pd.Index([])\n",
    "        final_up = up_in_top5\n",
    "        final_down = down_with_median     \n",
    "    \n",
    "    # SO now we have the outliers!\n",
    "    print \"    {}: {} up {} down {} top5\".format(\n",
    "        sample_expression.name,\n",
    "        len(final_up),\n",
    "        len(final_down),\n",
    "        len(top5_genes)\n",
    "    )\n",
    "\n",
    "    result =  {\n",
    "            \"expression_thresholds\":expression_thresholds,\n",
    "            \"final_up_idx\":final_up.index,\n",
    "            \"final_down_idx\":final_down.index,\n",
    "           }\n",
    "    # if expression & variance filters used, also pass sample_expression and filtered genes\n",
    "    if(is_filtered):\n",
    "        result[\"sample_expression\"] = sample_expression\n",
    "        result[\"filteredgenes\"] = filteredgenes\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print outlier results into the combined dataframe of everything\n",
    "# Takes the two outlier results dictionaries and the percentiles series\n",
    "def make_result_df(pancan_dict, disease_result_dict, percentiles):\n",
    "\n",
    "    # an empty dict for disease_specific_result indicates we're skipping disease_specific\n",
    "    skip_disease = (disease_result_dict == {})\n",
    "                      \n",
    "    result = pd.DataFrame(pancan_dict[\"sample_expression\"])\n",
    "\n",
    "    # 'sample' column - rename from sample ID to \"sample\"\n",
    "    result.rename(columns={pancan_dict[\"sample_expression\"].name:\"sample\"}, inplace=True)\n",
    "\n",
    "    # Set top 5 column\n",
    "    # TODO - there is probably a better way to do this then clearing it then filling in the correct ones\n",
    "    result.set_value(result.index, \"is_top_5\", \"\")\n",
    "    result.set_value(top5_genes, \"is_top_5\", \"top5\")\n",
    "\n",
    "    # Cohort thresholds\n",
    "    result[\"pc_low\"] = pancan_dict[\"expression_thresholds\"][\"low\"]\n",
    "    result[\"pc_median\"] = pancan_dict[\"expression_thresholds\"][\"median\"]\n",
    "    result[\"pc_high\"] = pancan_dict[\"expression_thresholds\"][\"high\"]\n",
    "\n",
    "    # outlier status\n",
    "    result.set_value(result.index, \"pc_outlier\", \"\")\n",
    "    result.set_value(pancan_dict[\"final_up_idx\"], \"pc_outlier\", \"pc_up\")\n",
    "    result.set_value(pancan_dict[\"final_down_idx\"], \"pc_outlier\", \"pc_down\")\n",
    "\n",
    "    # filtered genes\n",
    "    result.set_value(result.index, \"pc_is_filtered\", \"pc_dropped\") # set all genes as drop\n",
    "    result.set_value(pancan_dict[\"filteredgenes\"], \"pc_is_filtered\", \"\") # and then keep those that filter retained\n",
    "\n",
    "    if(not skip_disease):\n",
    "        # disease specific columns\n",
    "        result[\"pd_low\"] = disease_result_dict[\"expression_thresholds\"][\"low\"]\n",
    "        result[\"pd_median\"] = disease_result_dict[\"expression_thresholds\"][\"median\"]\n",
    "        result[\"pd_high\"] = disease_result_dict[\"expression_thresholds\"][\"high\"]\n",
    "        # disease outlier column\n",
    "        result.set_value(result.index, \"pd_outlier\", \"\")\n",
    "        result.set_value(disease_result_dict[\"final_up_idx\"], \"pd_outlier\", \"pd_up\")\n",
    "        result.set_value(disease_result_dict[\"final_down_idx\"], \"pd_outlier\", \"pd_down\")\n",
    "    \n",
    "    # percentile column - will match indices regardless of order\n",
    "    result[\"pc_percentile\"] = percentiles\n",
    "    \n",
    "    # TODO sometime later - if requested - also add pandisease filter columns\n",
    "    # eg pd_is_filtered (pd_dropped, \"\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Percentile analysis : what is the percentile rank of the sample's genes within the cohort?\n",
    "\n",
    "binned_cohort = pd.read_hdf(c[\"cohort\"][\"percentiles\"])\n",
    "sample_percentiles = binned_cohort.apply(get_sample_quantile, axis=0, sample_df=expression, sample_id=sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Get the pan-cancer outlier results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "top5_genes = sample_top5percent_genes(expression[sample_id])\n",
    "\n",
    "final_pancan = get_outliers(\n",
    "                                expression[sample_id], \n",
    "                                json_3[\"pancan_thresholds\"],\n",
    "                                top5_genes,\n",
    "                                True,  # pancan - use expression variance filters\n",
    "                                json_3[\"pancan_filtered_genes\"]\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For each of the personalized cohorts that are present, get their outlier results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "personalized_thresholds = [\n",
    "    \"pandis_thresholds\",\n",
    "    \"first_degree_thresholds\",\n",
    "    \"first_and_second_degree_thresholds\",\n",
    "    \"nof1_disease_thresholds\"\n",
    "]\n",
    "\n",
    "personalized_results = {}\n",
    "how_many_cohorts = 0\n",
    "\n",
    "for threshold in personalized_thresholds:\n",
    "    if(json_3[threshold]):\n",
    "        how_many_cohorts += 1\n",
    "        print threshold\n",
    "        personalized_results[threshold] = get_outliers(expression[sample_id], \n",
    "                                        json_3[threshold],\n",
    "                                        top5_genes\n",
    "                                        # personalized - Don't use expression variance filters\n",
    "                                        )\n",
    "    else:\n",
    "        print \"{}: personalized cohort not found, skipping\".format(threshold) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Store the personalized outliers in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# makes up , down outliers key from final_up_idx, final_down_idx. Cohort names will be:\n",
    "# ['pandis_outliers','nof1_disease_outliers','first_degree_outliers','first_and_second_degree_outliers']\n",
    "\n",
    "j[\"personalized_outliers\"] = {}\n",
    "for thresholdname in personalized_results.keys():\n",
    "    cohortname = thresholdname.replace(\"thresholds\", \"outliers\")\n",
    "    j[\"personalized_outliers\"][cohortname] = {}\n",
    "    for outlier in [\"up\", \"down\"]:\n",
    "        j[\"personalized_outliers\"][cohortname][outlier] = list(\n",
    "            personalized_results[thresholdname][\"final_{}_idx\".format(outlier)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Set the personalized expression thresholds that will appear in the CSV outlier results. These were originally the pan-disease thresholds. \n",
    "However, since the \"pan-disease outliers\" are now consensus outliers, and not derivable from these thresholds, it's misleading to keep them in the file. Leave the columns there, but set them to be NaN.\n",
    "\n",
    "(Personalized thresholds for every personal cohort are available in the output from step 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_personalized = {}\n",
    "final_personalized[\"expression_thresholds\"] = final_pancan[\"expression_thresholds\"].applymap(\n",
    "    lambda x: \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then, get the final personalized up and down outliers.\n",
    "We get a consensus (ie, intersection of outliers) that varies based on how many personalized cohorts we have.\n",
    "\n",
    "We marked the alerts / failures based on too few cohorts in the previous threshold generation step.\n",
    "\n",
    "- 0 cohorts: Treat as if 0 pandisease outliers were found\n",
    "- 1 cohort: Treat it as if 0 pandisease outliers were found (since we don't have consensus).\n",
    "- 2 cohorts: intersection of outliers (need 2 out of 2)\n",
    "- 3 cohorts: 2 out of 3 \n",
    "- 4 cohorts: 2 out of 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "j[\"personalized_consensus_counts\"] = {}\n",
    "\n",
    "if(how_many_cohorts in [0,1]):\n",
    "    final_personalized[\"final_up_idx\"] = pd.Index([])\n",
    "    final_personalized[\"final_down_idx\"] = pd.Index([])\n",
    "\n",
    "elif(how_many_cohorts in [2,3,4]):\n",
    "    for outlier_type in [\"up\", \"down\"]:\n",
    "        all_genes = collections.Counter()\n",
    "        for cohort in personalized_results.values():\n",
    "            all_genes.update(cohort[\"final_{}_idx\".format(outlier_type)])\n",
    "        consensus_genes = {k:v for k,v in all_genes.iteritems() if v >= 2}\n",
    "        final_personalized[\"final_{}_idx\".format(outlier_type)] = pd.Index(consensus_genes)\n",
    "        j[\"personalized_consensus_counts\"][\"{}_outliers\".format(outlier_type)] = consensus_genes\n",
    "else:\n",
    "    print(\"Found {} cohorts; this should never happen!\".format(how_many_cohorts))\n",
    "    raise KeyboardInterrupt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"Pancancer results: {}\".format(final_pancan.keys())\n",
    "print \"Personalized results: {}\".format(final_personalized.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, combine the results into a string-based dataframe; save it both as a CSV and in the final json output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oa_results = make_result_df(final_pancan, final_personalized,sample_percentiles)\n",
    "oa_results_asString = oa_results.applymap(lambda x: x if (type(x) == str) else \"%.12g\" % x )\n",
    "j[\"outlier_results\"] = json.loads(oa_results_asString.to_json(orient='columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print \"Exporting to {}\".format(c[\"file\"][\"outlier_results\"])\n",
    "\n",
    "oa_results.to_csv(c[\"file\"][\"outlier_results\"],\n",
    "                    sep=\"\\t\",\n",
    "                    index_label=\"Gene\")\n",
    "\n",
    "with open(c[\"json\"][\"4.0\"], \"w\") as jsonfile:\n",
    "    json.dump(j, jsonfile, indent=2)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
