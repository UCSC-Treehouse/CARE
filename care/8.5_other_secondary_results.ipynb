{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "Originally named 8.5_parse-vcf.ipynb\n",
    "\n",
    "Parse various outputs from secondary and make it available to the summary documents.\n",
    "\n",
    "-  Parse VCF:\n",
    "    Takes the vcf file for a sample and makes a human-readable output.\n",
    "    [\"Don't write home-brewed VCF parsing scripts. It never ends well.\"](https://gatkforums.broadinstitute.org/gatk/discussion/1268/what-is-a-vcf-and-how-should-i-interpret-it)\n",
    "   \n",
    "\n",
    " - Parse fusion results\n",
    "\n",
    "- Parse FLT3-ITD results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "from distutils.version import LooseVersion\n",
    "\n",
    "with open(\"conf.json\",\"r\") as conf:\n",
    "    c=json.load(conf)\n",
    "sample_id = c[\"sample_id\"]    \n",
    "print(\"Running on sample: {}\".format(sample_id))\n",
    "logging.basicConfig(**c[\"info\"][\"logging_config\"])\n",
    "\n",
    "def and_log(s):\n",
    "    logging.info(s)\n",
    "    return s\n",
    "\n",
    "j = {}\n",
    "print and_log(\"Running Parse Secondary Results: VCF, Fusion, FLT3-ITD Detection...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Basedir - must include \"-*\" at the end for glob to find\n",
    "# Finds the most recent version of this directory\n",
    "# and looks for the fixed file path within it\n",
    "def locate_secondary_file(basedir, filepath):\n",
    "    \n",
    "    all_vardirs = sorted(glob.glob(os.path.join(c[\"dir\"][\"secondary\"], basedir)),\n",
    "                        key=LooseVersion)\n",
    "    # Get the file, or most recent if there are more than one.\n",
    "    if len(all_vardirs) >= 1:\n",
    "        result = os.path.join(all_vardirs[-1], filepath)\n",
    "        if not os.access(result, os.R_OK): # Check that the file is present and readable\n",
    "            print and_log(\"Secondary output dir for {} was located but the desired file {} was not readable.\".format(\n",
    "                basedir, filepath))\n",
    "            return \"\"\n",
    "    else:\n",
    "        print and_log(\"No secondary output dir {} located for this sample.\".format(basedir))\n",
    "        result = \"\"\n",
    "    return result\n",
    "\n",
    "\n",
    "# The format of the info field is k=v, delimited by ;\n",
    "# (although a Flag item may be present with no = sign but simply k=v;k;k=v)\n",
    "# All the info items we use - gene, type, and aa change - are in the EFF sub-field.\n",
    "# The format of the EFF sub-field is k(v|v|v),k(v|v|v)\n",
    "def parse_info(info):\n",
    "    result = {}\n",
    "\n",
    "    info_items = map(lambda x: x.split(\"=\"), info.split(\";\"))\n",
    "    # For now, drop all Flag items as we don't need them anyhow\n",
    "    info_dict = {k : v for (k, v) in filter(lambda x: len(x) ==2, info_items) }\n",
    "    \n",
    "    # Get the EFF items and parse each\n",
    "    # Note the first item is \"k(v\"  and the last is \"v)\", because we don't care \n",
    "    eff_items = map(lambda x: x.split(\"|\"),  info_dict[\"EFF\"].split(\",\"))\n",
    "        \n",
    "    # We report the gene and type from the first EFF item only\n",
    "    first_eff = eff_items.pop(0)\n",
    "    result[\"gene\"] = first_eff[5]\n",
    "    result[\"type\"] = first_eff[1]\n",
    "\n",
    "    # Collect AA changes, starting with the first item. Then collect AA changes only from\n",
    "    # subsequent items when their gene and type are the same\n",
    "    found_aa_changes = set([first_eff[3]])\n",
    "    \n",
    "    for eff in eff_items:\n",
    "        if (result[\"gene\"] == eff[5]) and (result[\"type\"] == eff[1]):\n",
    "            found_aa_changes.add(eff[3])\n",
    "    \n",
    "    result[\"aa change\"] = \"|\".join(found_aa_changes)\n",
    "    return result\n",
    "\n",
    "# parse the vcf 'unknown' field\n",
    "def parse_unknown(uk):\n",
    "    items = uk.split(\":\")\n",
    "    return {\n",
    "     \"genotype\": items[0],\n",
    "     \"ref reads\": items[2],\n",
    "     \"alt reads\": items[4]\n",
    "    }\n",
    "    \n",
    "# parse the FORMAT and 'unknown' fields into their key value pairs\n",
    "def extra_fields(fmt, unknown):\n",
    "    fmt_fields = fmt.split(\":\")\n",
    "    fmt_values = unknown.split(\":\")\n",
    "    return dict(zip(fmt_fields, fmt_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# FLT3-ITD report\n",
    "\n",
    "j[\"flt3itd_file\"] = locate_secondary_file(\"jpfeil-jfkm-*\", \"FLT3-ITD.report\")\n",
    "j[\"flt3itd_events\"] = []\n",
    "\n",
    "j[\"flt3itd_keys\"] = [\"Type\",\"Abnormal\",\"Normal\"]\n",
    "if not j[\"flt3itd_file\"]:\n",
    "    print \"No FLT3-ITD report file present!\"\n",
    "else:\n",
    "    with open(j[\"flt3itd_file\"], \"r\") as f:\n",
    "        reader = csv.DictReader(f, delimiter=\"\\t\")\n",
    "        for row in reader:\n",
    "            j[\"flt3itd_events\"].append({k: row[k] for k in j[\"flt3itd_keys\"]})\n",
    "            \n",
    "j[\"flt3itd_events\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Fusions\n",
    "j[\"fusion_file\"] = locate_secondary_file(\"ucsctreehouse-fusion-*\", \"star-fusion-gene-list-filtered.final\")\n",
    "j[\"fusions\"] = []\n",
    "\n",
    "# Save only selected fields\n",
    "fusion_keys = [\"#FusionName\",\"JunctionReadCount\",\"SpanningFragCount\"]\n",
    "j[\"fusion_keys\"] = map(lambda x: x.replace(\"#\", \"\"), fusion_keys)\n",
    "\n",
    "if not j[\"fusion_file\"]:\n",
    "    print \"No fusion file present!\"\n",
    "else:\n",
    "    with open(j[\"fusion_file\"], \"r\") as f:\n",
    "        reader = csv.DictReader(f, delimiter=\"\\t\")\n",
    "        for row in reader:\n",
    "            j[\"fusions\"].append({k.replace(\"#\", \"\"): row[k] for k in fusion_keys})\n",
    "j[\"fusions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Modified from https://github.com/UCSC-Treehouse/analysis-methods/blob/master/script/parse_vcf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Variant Call\n",
    "j[\"vcf_file\"] = locate_secondary_file(\"ucsctreehouse-mini-var-call-*\", \"mini.ann.vcf\")\n",
    "print j[\"vcf_file\"]\n",
    "\n",
    "if not j[\"vcf_file\"]:\n",
    "    print \"No VCF file present!\"\n",
    "else:\n",
    "    variants = []\n",
    "\n",
    "    default_FORMAT=\"\"\n",
    "    vcf_fields=[\"CHROM\",\"POS\",\"ID\",\"REF\",\"ALT\",\"QUAL\",\"FILTER\",\"INFO\",\"FORMAT\",\"unknown\"]\n",
    "    \n",
    "    with open(j[\"vcf_file\"], \"r\") as f:\n",
    "        reader = csv.DictReader((row for row in f if not row.startswith('#')),\n",
    "                               fieldnames=vcf_fields,\n",
    "                               delimiter=\"\\t\")\n",
    "        # Get the VCF fields\n",
    "        for row in reader:\n",
    "            if default_FORMAT:\n",
    "                if not row[\"FORMAT\"] == default_FORMAT:\n",
    "                    print(\"ERROR! FORMAT field changed from expected!\")\n",
    "                    print(\"Got: {} Expected: {}\".format(row[\"FORMAT\"], default_FORMAT))\n",
    "                    raise IOError(\"Unexpected change to FORMAT field in VCF file.\")\n",
    "            else:\n",
    "                default_FORMAT = row[\"FORMAT\"]\n",
    "          \n",
    "            row_details = parse_info(row[\"INFO\"])\n",
    "            \n",
    "            row_details.update(parse_unknown(row[\"unknown\"]))\n",
    "            row_details[\"quality\"] = row[\"QUAL\"]\n",
    "            row_details[\"chr\"] = row[\"CHROM\"]\n",
    "            row_details[\"pos\"] = row[\"POS\"]\n",
    "            row_details[\"ref\"] = row[\"REF\"]\n",
    "            row_details[\"alt\"] = row[\"ALT\"]\n",
    "            row_details.update(extra_fields(row[\"FORMAT\"], row[\"unknown\"]))\n",
    "            \n",
    "            variants.append(row_details)\n",
    "            \n",
    "    field_order= \"gene,aa change,type,genotype,ref reads,alt reads,quality,chr,pos,ref,alt\".split(\",\")\n",
    "    field_order += default_FORMAT.split(\":\")\n",
    "\n",
    "    j[\"variants\"] = variants\n",
    "    # And also store the field_order so it's easier to display downstream\n",
    "    j[\"primary_fields\"] = field_order[0:3]\n",
    "    j[\"extra_fields\"] = field_order[3:]\n",
    "        \n",
    "    ### Print the output ###   \n",
    "    # First, print just the INFO\n",
    "    print( \"\\t\".join(field_order[0:3]))\n",
    "    for item in variants:\n",
    "        print(\"\\t\".join(map(lambda x: item[x], field_order[0:3])))\n",
    " \n",
    "    # Then print the whole thing\n",
    "    print\n",
    "    print \"\\t\".join(field_order)\n",
    "    for item in variants:\n",
    "        print(\"\\t\".join(map(lambda x: item[x], field_order)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(c[\"json\"][\"8.5\"], \"w\") as jsonfile:\n",
    "    json.dump(j, jsonfile, indent=2)\n",
    "    \n",
    "print and_log(\"Parse secondary results - Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
