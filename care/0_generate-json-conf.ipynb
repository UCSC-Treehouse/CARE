{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this will create a json file conf.json which contains all the paths necessary for a sample.\n",
    "\n",
    "# and the sample and cohort and stuff.\n",
    "import os\n",
    "import json\n",
    "import errno\n",
    "import logging\n",
    "import hashlib # for md5 sums\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "configuration_file_name = \"conf.json\"\n",
    "\n",
    "# If a conf.json already exists in the pwd, use that to get the basic conf info\n",
    "try:\n",
    "    with open(configuration_file_name,\"r\") as conf:\n",
    "        c=json.load(conf)\n",
    "except IOError:\n",
    "    c = {}\n",
    "    c[\"dir\"] = {}\n",
    "\n",
    "    # Set up the conf with the basic details\n",
    "    c[\"sample_id\"] = os.getenv(\"TREEHOUSE_SAMPLE_ID\")\n",
    "\n",
    "# possible incoming values from os.getenv are a string or None.\n",
    "# Ensure that all values in the conf are strings (it's ok if medbook prefix is empty)\n",
    "# If values aren't present, set them to a test value and also run in dryrun mode\n",
    "if not c[\"sample_id\"]:\n",
    "    print(\"Sample ID can't be {}; setting it to a test value.\".format(c[\"sample_id\"]))\n",
    "    c[\"sample_id\"] = \"TEST_SAMPLE_1\"\n",
    "\n",
    "print(\"Creating configuration file for sample {}\".format(c[\"sample_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "if not \"info\" in c: # Don't clear info if exists, so we can check the git hash\n",
    "    c[\"info\"] = {}\n",
    "c[\"file\"]={}\n",
    "\n",
    "# Interquartile range multiplier: \n",
    "c[\"info\"][\"iqr_multiplier\"] = 1.5\n",
    "\n",
    "# For expression filter, what proportion should have expression=0 to drop gene?\n",
    "c[\"info\"][\"proportion_unexpressed_filter_cutoff\"] = 0.8\n",
    "# for variance filter, what percent of genes (sorted by variance) should we drop?\n",
    "c[\"info\"][\"variance_filter_cutoff\"]=0.2\n",
    "\n",
    "c[\"error_delim\"]=\"(PRINTTHIS)\" # Surround error messages with this and they will be printed in the console\n",
    "c[\"info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "# this should be used for all paths (to dirs and files) that are used in more than one notebook\n",
    "\n",
    "#### Base Paths ###\n",
    "\n",
    "# Cohort dir\n",
    "c[\"dir\"][\"cohort\"] = os.path.join(os.sep, \"work\", \"cohort\")\n",
    "\n",
    "c[\"dir\"][\"ref\"]=os.path.join(os.sep, \"work\", \"references\")\n",
    "\n",
    "### sample_specific paths\n",
    "\n",
    "c[\"dir\"][\"sample\"]=\".\" # use the CWD\n",
    "\n",
    "c[\"file\"][\"conf\"]=os.path.join(c[\"dir\"][\"sample\"], configuration_file_name)\n",
    "\n",
    "### Secondary output for this sample\n",
    "c[\"dir\"][\"secondary\"]=os.path.join(os.sep, \"work\", \"inputs\", c[\"sample_id\"], \"secondary\")\n",
    "\n",
    "# temporary dir for intra-notebook tmp files, eg, to be passed to R scripts\n",
    "c[\"dir\"][\"temp\"]=\".\" # Testing : use the CWD?\n",
    " \n",
    "\n",
    "## Original input file from rna-seq output\n",
    "c[\"file\"][\"rsem_genes.results\"]=os.path.join(c[\"dir\"][\"sample\"], \"rsem_genes.results\")\n",
    "\n",
    "# Log file for errors etc.\n",
    "c[\"file\"][\"log\"]=os.path.join(c[\"dir\"][\"sample\"], \"log.txt\")\n",
    "\n",
    "# Failure flag--if this json file is present, the tertiary has failed\n",
    "# (but was not halted). Use this for a QC failure, for example.\n",
    "# the format of the file is reason: { dict with each step number as the key}\n",
    "# { \"reason\" : {  \"2.0\": \"matches existing sample\", 4.0\" : \"not enough genes\"}}\n",
    "c[\"file\"][\"flag_analysis_failed\"] = os.path.join( c[\"dir\"][\"sample\"], \"ANALYSIS_FAILED.json\")\n",
    "print((\"If the tertiary output fails QC checks,\"\n",
    "       \"check the {} file for details\".format(c[\"file\"][\"flag_analysis_failed\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sanity check:\n",
    "# Confirm that input dirs (secondary, references, cohort) are a) present and b) readonly\n",
    "\n",
    "readonly_dirs = [c[\"dir\"][\"cohort\"], c[\"dir\"][\"secondary\"], c[\"dir\"][\"ref\"]]\n",
    "for dir in readonly_dirs:\n",
    "    if not os.path.isdir(dir):\n",
    "        raise IOError(c[\"error_delim\"]+\"Required directory {} isn't present.\\n\".format(dir)+\n",
    "                        \"Please mount this as a :ro volume to continue.\"+c[\"error_delim\"])   \n",
    "    if os.access(dir, os.W_OK):\n",
    "        raise IOError(c[\"error_delim\"]+\"Volume {} is mounted read-write; refusing to continue.\\n\".format(dir)+\n",
    "                        \"Please mount this volume with :ro to enforce read-only.\"+c[\"error_delim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set up the logging configuration for later notebooks\n",
    "c[\"info\"][\"logging_config\"] = dict(\n",
    "    filename=c[\"file\"][\"log\"],\n",
    "    level=logging.INFO,\n",
    "    format='%(message)s'\n",
    ")\n",
    "logging.basicConfig(**c[\"info\"][\"logging_config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Logging: Basic info\n",
    "logging.info(\"Tertiary Analysis Results\\n-------------------------\")\n",
    "now = time.strftime(\"%Y/%m/%d %H:%M %Z\")\n",
    "logging.info(\"Started: {}\".format(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### cohort-specific paths - files under c[cohort]\n",
    "c[\"cohort\"]={}\n",
    "\n",
    "\n",
    "# Clinical data for cohort\n",
    "c[\"dir\"][\"cohort_clinical\"] = os.path.join(c[\"dir\"][\"cohort\"], \"clinical\")\n",
    "\n",
    "# Path to the hd5 file containing the expression data for this cohort.\n",
    "# This file is used for outlier analysis and is used by default for Tumormap placement.\n",
    "# Not expression & variance filtered\n",
    "c[\"cohort\"][\"expression_hd5\"] = os.path.join(c[\"dir\"][\"cohort\"],\"cohort.hd5\")\n",
    "\n",
    "# cohort percentiles file, for adding the percentile column to outlier analysis\n",
    "c[\"cohort\"][\"percentiles\"] = os.path.join(c[\"dir\"][\"cohort\"],\"percentiles.hd5\")\n",
    "\n",
    "# all-by-all correlation matrix - for step 2.2\n",
    "c[\"cohort\"][\"all_by_all_tsv\"] = os.path.join(\n",
    "    c[\"dir\"][\"cohort\"],\n",
    "    \"all_by_all_correlations.tsv\")\n",
    "\n",
    "# Essential clinical data - for step2.6\n",
    "c[\"cohort\"][\"essential_clinical\"] = os.path.join(\n",
    "    c[\"dir\"][\"cohort\"],\n",
    "    \"clinical.tsv\")\n",
    "\n",
    "# Get the compendium 0 threshold if it exists.\n",
    "# This is a compendium v3 specific thing.\n",
    "# keep it as a string because we're just writing it to json anyhow.\n",
    "try:\n",
    "    with open(os.path.join(c[\"dir\"][\"cohort\"], \"cohort.zero.threshold.value.txt\"), \"r\") as zt:\n",
    "        c[\"info\"][\"cohort_zero_threshold\"] = zt.read().rstrip()\n",
    "except IOError:\n",
    "    c[\"info\"][\"cohort_zero_threshold\"] = \"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sample-specific info from sample_info.json\n",
    "# This replaces diagnosed_disease.txt and id_on_tumormap.txt \n",
    "sample_info_json_file = os.path.join(c[\"dir\"][\"sample\"],\"sample_info.json\")\n",
    "try:\n",
    "    with open(sample_info_json_file, \"r\") as f:\n",
    "        sample_info = json.load(f)\n",
    "        print(\"Loading sample info from json...\")\n",
    "except IOError as e: # no json file?? Should always be present...\n",
    "        print(\"Couldn't load sample_info.json: {}\".format(e))\n",
    "        raise\n",
    "\n",
    "# The self-sample, if it already exists on the tumormap, may have a different ID than the ID used in\n",
    "# processing. Set the ID that tumormap looks for here.\n",
    "if sample_info[\"alias\"]:\n",
    "    c[\"info\"][\"id_for_tumormap\"] = sample_info[\"alias\"]\n",
    "else:\n",
    "    c[\"info\"][\"id_for_tumormap\"] = c[\"sample_id\"]\n",
    "    \n",
    "tid_str=\"Expecting this sample to appear on Tumormap as '{}'\".format(c[\"info\"][\"id_for_tumormap\"])\n",
    "print(tid_str)\n",
    "logging.info(tid_str)\n",
    "\n",
    "# Diagnosed disease, if available.\n",
    "if sample_info[\"disease\"]:\n",
    "    c[\"info\"][\"disease\"] = sample_info[\"disease\"]\n",
    "    print(\"Found a diagnosis of {} for this sample.\".format(c[\"info\"][\"disease\"]))\n",
    "else:\n",
    "    c[\"info\"][\"disease\"] = None\n",
    "    \n",
    "# roll-up cohort, if available.\n",
    "# Check that the all of the provided roll-up cohort samples are present in the cohort clinical file.\n",
    "if sample_info[\"rollup\"]:\n",
    "    rollup_samples = set(sample_info[\"rollup\"])\n",
    "    cohort_samples = set(pd.read_csv(c[\"cohort\"][\"essential_clinical\"], sep=\"\\t\")[\"th_sampleid\"])\n",
    "    extra_samples_in_rollup = rollup_samples - cohort_samples\n",
    "    if len(extra_samples_in_rollup) == 0:\n",
    "        c[\"info\"][\"rollup\"] = sorted(list(rollup_samples))\n",
    "    else:\n",
    "        raise IOError(c[\"error_delim\"] +\n",
    "                      \"Error: Found samples in the rollup cohort that are not in the compendium:\\n\".format(dir) +\n",
    "                      \"{}\".format(extra_samples_in_rollup) + c[\"error_delim\"])\n",
    "else:\n",
    "    c[\"info\"][\"rollup\"] = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Tumormap placement-specific paths & info\n",
    "# For step 2.0\n",
    "\n",
    "c[\"dir\"][\"tumormap\"] = os.path.join(c[\"dir\"][\"cohort\"], \"tumormap\")\n",
    "\n",
    "\n",
    "# All files are present in the 'tumormap' subdirectory of the reference cohort\n",
    "# When using an alternate tumormap background cohort, a docker volume should be mounted to alias that subdirectory.\n",
    "# Either or both of the background hdf or tsv files may be present; a tsv will be used in preference to hdf.\n",
    "# If the HDF is used, its genes will be filtered by the gene filter file. If the TSV is used, it will not be filtered;\n",
    "# the expectation is that expression-variance filters have already been applied.\n",
    "\n",
    "c[\"tumormap\"] = {}\n",
    "c[\"tumormap\"][\"background_hdf\"] = os.path.join(c[\"dir\"][\"tumormap\"], \"tumormap_expression.hd5\" )\n",
    "c[\"tumormap\"][\"background_tsv\"] = os.path.join(c[\"dir\"][\"tumormap\"], \"tumormap_expression.tsv\" )\n",
    "\n",
    "# Get info for tumormap.\n",
    "# Should contain keys: url, name, expression_md5, mcs_similarity_threshold                                             \n",
    "tumormap_info_file=os.path.join(c[\"dir\"][\"tumormap\"], \"tumormap_info.json\" )\n",
    "with open(tumormap_info_file, \"r\") as f:\n",
    "    c[\"tumormap\"][\"info\"] = json.load(f)\n",
    "    \n",
    "\n",
    "                                           \n",
    "# Tumormap-specific list of clinical data. Must have at minimum:\n",
    "# - sample column labeled \"th_sampleid\"\n",
    "# - disease column labeled \"disease\"\n",
    "# - age at diagnosis column labeled \"age_at_dx\"\n",
    "# This list contains the samples on the tumormap (which may be a superset or subset of those in the outlier cohort.)\n",
    "# It's used to determine the pan-disease cohort based on tumormap placement.\n",
    "\n",
    "c[\"tumormap\"][\"essential_clinical\"] = os.path.join(\n",
    "    c[\"dir\"][\"tumormap\"],\n",
    "    \"clinical.tsv\")\n",
    "\n",
    "\n",
    "\n",
    "# Expression & variance filters were applied to tumormap_expression.hd5, and the list of genes that passed the filters\n",
    "# was retained. Thus, when we use the (unfiltered) tumormap_expression.hd5 cohort for tumormap placement, we can\n",
    "# recreate the filter results.\n",
    "# proportion unexpressed 0.8, variance cutoff 0.2\n",
    "c[\"tumormap\"][\"filtered_genes_to_keep\"] = os.path.join(c[\"dir\"][\"tumormap\"],\n",
    "                                                     \"filtered_genes_to_keep.tsv\")\n",
    "\n",
    "# Euclidean positions of the cohort, for visual tumormap placement\n",
    "c[\"tumormap\"][\"xy_coords\"] = os.path.join(c[\"dir\"][\"tumormap\"],\"assignments0.tab\")\n",
    "\n",
    "# Tumormap disease-to-color json file (optional)\n",
    "c[\"tumormap\"][\"disease_color_map\"]=os.path.join(c[\"dir\"][\"tumormap\"], \"tumormap_disease_colors.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get info for the compendium.\n",
    "# Should contain keys: description (Free text/HTML for summary document), name, and expression_md5 -\n",
    "# the md5sum of the cohort.hd5 file.\n",
    "# and mcs_similarity_threshold - the threshold for when an MCS is sufficiently similar (95% percentile).\n",
    "with open(os.path.join(c[\"dir\"][\"cohort\"],\"compendium_info.json\"), \"r\") as f:\n",
    "    c[\"cohort\"][\"info\"] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# intermediate outputs\n",
    "\n",
    "# 1 - convert tpm hugo\n",
    "\n",
    "# INPUT single-column TPM file with non-unique hugo names\n",
    "c[\"file\"][\"tpm_hugo\"]=os.path.join(c[\"dir\"][\"sample\"], \"rsem.genes.tpm.hugo.tab\")\n",
    "\n",
    "# OUTPUT TPM hugo file normalized with log2(n+1) and unique hugo names\n",
    "# This is the canonical \"sample expression\" file\n",
    "c[\"file\"][\"tpm_hugo_norm_uniq\"]=os.path.join(\n",
    "    c[\"dir\"][\"sample\"], \n",
    "    \"rsem.genes.tpm.hugo.log2plus1.dedupe.tab\")\n",
    "\n",
    "# REFERENCE\n",
    "\n",
    "# Reference files that are constant across submissions\n",
    "c[\"ref_file\"] = {}\n",
    "\n",
    "# Ensembl IDs, 1 per line, first line is gene_id\n",
    "c[\"ref_file\"][\"ensembl_id_list\"]=os.path.join(c[\"dir\"][\"ref\"], \"ensembl_ids.txt\")\n",
    "\n",
    "# header entries from rsem_genes.results, 1 per line, first line is gene_id\n",
    "c[\"ref_file\"][\"rsem_genes.results_header\"]=os.path.join(c[\"dir\"][\"ref\"], \"rsem_genes.results.header.txt\")\n",
    "\n",
    "# First column: Hugo, ensembl_hugo_NA_key (ie, \"NA\") if none. Second column : ensembl ID\n",
    "c[\"ref_file\"][\"ensembl_hugo_mapping_file\"] = os.path.join(c[\"dir\"][\"ref\"], \"EnsGeneID_Hugo_Observed_Conversions.txt\")\n",
    "\n",
    "# col 1: Sample ID. col 2: comma-separated list of mutations in that sample\n",
    "c[\"ref_file\"][\"TCGA_non_silent_cancer_mutations_by_sample\"] = os.path.join(\n",
    "    c[\"dir\"][\"ref\"], \n",
    "    \"TH_THR_and_TARGET_NonSilentMutationsInCancerGenesBySample_2019-03-07_03.59.59PM.txt\")\n",
    "\n",
    "# Input pathway file msigdb.v5.2.symbols.gmt\n",
    "c[\"ref_file\"][\"msigdb_pathway_file\"] = os.path.join(\n",
    "    c[\"dir\"][\"ref\"],\n",
    "    \"msigdb.v5.2.symbols.gmt\")\n",
    "\n",
    "# col 1: Pathway name (string); col 2: blank or pathway  group. No header line.\n",
    "c[\"ref_file\"][\"curated_pathways_druggable_genes\"] = os.path.join( c[\"dir\"][\"ref\"],\n",
    "    \"tertiary-references\", \"curatedPathwaysContainingFDA_druggableGenes.txt\" )\n",
    "\n",
    "# col 1: gene (hugo symbol); col 2: group (string)\n",
    "c[\"ref_file\"][\"druggable_genes_by_category\"] = os.path.join( c[\"dir\"][\"ref\"],\n",
    "    \"tertiary-references\", \"treehouseDruggableGenes_2019-06-12.txt\" )\n",
    "\n",
    "# qc_reporting reference ranges\n",
    "c[\"ref_file\"][\"reference_ranges\"] = os.path.join(c[\"dir\"][\"ref\"],\n",
    "    \"qc_report\", \"QC_reference_ranges_2019_04_23.tsv\")\n",
    "\n",
    "# qc_reporting rin score\n",
    "c[\"ref_file\"][\"redcap_download_rinscore\"] = os.path.join(c[\"dir\"][\"ref\"],\n",
    "    \"qc_report\", \"redcap_combined_sample_donor_data_downloaded_via_API_2019-02-06_06.19.14PM.txt\")\n",
    "\n",
    "# If an alternate tumormap file exists in the sample dir, set that as the expression file\n",
    "# to use when running the tumormap call.\n",
    "# If not, use the processed sample expression file.\n",
    "\n",
    "# Typically the expression to place against tumormap is the standard n-of-1\n",
    "# expression file generated by step 1. Sometimes however an alternate expression file needs\n",
    "# to be used (eg if it is batch corrected). If a file is present at this path, it means that\n",
    "# it should be used as the expression to place against tumormap.\n",
    "c[\"file\"][\"alternate_tumormap_expression\"]=os.path.join(\n",
    "    c[\"dir\"][\"sample\"],\n",
    "    \"alternate_expression_for_tumormap.tsv\"     )\n",
    "\n",
    "# 2.0 output : TSV for tumormap attribute of sample->compendium similarity\n",
    "c[\"file\"][\"sample_vs_compendium_tumormap_attribute\"] = (\n",
    "    \"Correlations_{}_vs_{}.tsv\".format(c[\"sample_id\"], c[\"cohort\"][\"info\"][\"name\"]))\n",
    "\n",
    "# 2.5 - tumormap report details - report file\n",
    "c[\"file\"][\"tumormap_report\"]=os.path.join(c[\"dir\"][\"sample\"],\"{}.tumormap_report.txt\".format(c[\"sample_id\"]))\n",
    "\n",
    "# 2.6 - Most similar samples mutation report\n",
    "\n",
    "# 3 - make thresholds\n",
    "\n",
    "# 4.0 - outlier analysis\n",
    "c[\"file\"][\"outlier_results\"]=os.path.join(c[\"dir\"][\"sample\"], \"outlier_results_{}\".format(c[\"sample_id\"]))\n",
    "\n",
    "# 4.5 - expression plots. Output folder for the pngs.\n",
    "c[\"dir\"][\"gene_expression_plots_dir\"]=os.path.join(c[\"dir\"][\"sample\"], \"expression_plots\")\n",
    "\n",
    "# 5 - gsea dgidb - pathway and gene files for gsea investigate gene sets\n",
    "\n",
    "gsea_dir = \"GSEA\"\n",
    "\n",
    "# Dictionary: keys are hugo symbols, values are (dgidb found gene name, [list of drugs])\n",
    "# see analysis-methods for creation scripts\n",
    "c[\"ref_file\"][\"dgidb_genes_and_drugs\"] = os.path.join( c[\"dir\"][\"ref\"],\n",
    "    \"HugoGenesVsDGIdbDrugs.json\")\n",
    "\n",
    "# Pathways with corresponding gene lists\n",
    "c[\"ref_file\"][\"h_symbols_pathway\"] = os.path.join( c[\"dir\"][\"ref\"], gsea_dir, \"h.all.v6.1.symbols.gmt\")\n",
    "c[\"ref_file\"][\"c2_cp_symbols_pathway\"] = os.path.join( c[\"dir\"][\"ref\"], gsea_dir, \"c2.cp.v6.1.symbols.gmt\")\n",
    "c[\"ref_file\"][\"msigdb_symbols_pathway\"] = os.path.join( c[\"dir\"][\"ref\"], gsea_dir, \"msigdb.v6.1.symbols.gmt\")\n",
    "\n",
    "# Pathway Descriptions\n",
    "c[\"ref_file\"][\"h_symbols_pathway_description\"] = os.path.join( \n",
    "    c[\"dir\"][\"ref\"], gsea_dir, \"h.all.v6.1.symbols.DESCRIPTIONS.gmt\")\n",
    "c[\"ref_file\"][\"c2_cp_symbols_pathway_description\"] = os.path.join( \n",
    "    c[\"dir\"][\"ref\"], gsea_dir, \"c2.cp.v6.1.symbols.DESCRIPTIONS.gmt\")\n",
    "\n",
    "# Gene Descriptions\n",
    "c[\"ref_file\"][\"hgnc_gene_description\"] = os.path.join( \n",
    "    c[\"dir\"][\"ref\"], gsea_dir, \"HGNC_gene_descriptions_2018-11-30.tsv\")\n",
    "\n",
    "# 7 - pathway xls\n",
    "c[\"file\"][\"7_out\"] = {}\n",
    "c[\"file\"][\"7_out\"][\"all_gene_aggregation\"]=os.path.join(c[\"dir\"][\"sample\"], \"allGeneAggregation.txt\")\n",
    "c[\"file\"][\"7_out\"][\"druggable_gene_aggregation\"]=os.path.join(c[\"dir\"][\"sample\"], \"druggableGeneAggregation.txt\")\n",
    "c[\"file\"][\"7_out\"][\"gene_set_aggregation\"]=os.path.join(c[\"dir\"][\"sample\"], \"GeneSetAggregation.txt\")\n",
    "c[\"file\"][\"7_out\"][\"gene_set_details_per_list\"]=os.path.join(c[\"dir\"][\"sample\"], \"GeneSetDetailsPerList.txt\")\n",
    "c[\"file\"][\"7_out\"][\"gsea_dgidb_output_excel\"]=os.path.join(\n",
    "    c[\"dir\"][\"sample\"], \"{}_gsea_dgidb_output.xlsx\".format(c[\"sample_id\"]))\n",
    "\n",
    "# Step 8 - generate automated leads\n",
    "c[\"file\"][\"automated_leads_identified\"] = os.path.join( c[\"dir\"][\"sample\"], \"automatedLeadsIdentified.tsv\")\n",
    "\n",
    "# Step 9 - generate report\n",
    "# input - templates to use\n",
    "# output - final html and files for summary and slides\n",
    "c[\"info\"][\"summary_template_name\"] = \"summary.template\"\n",
    "c[\"file\"][\"summary_html\"] = os.path.join(c[\"dir\"][\"sample\"], \"Summary.html\")\n",
    "c[\"info\"][\"slides_template_name\"] = \"slides.template\"\n",
    "c[\"file\"][\"slides_html\"] = os.path.join(c[\"dir\"][\"sample\"], \"Slides.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# paths to JSON files for each step\n",
    "c[\"json\"] = {}\n",
    "c[\"json\"][\"1\"] = os.path.join(c[\"dir\"][\"sample\"], \"1.json\")\n",
    "c[\"json\"][\"2.0\"] = os.path.join(c[\"dir\"][\"sample\"], \"2.0.json\")\n",
    "c[\"json\"][\"2.2\"] = os.path.join(c[\"dir\"][\"sample\"], \"2.2.json\")\n",
    "c[\"json\"][\"2.5\"] = os.path.join(c[\"dir\"][\"sample\"], \"2.5.json\")\n",
    "c[\"json\"][\"2.6\"] = os.path.join(c[\"dir\"][\"sample\"], \"2.6.json\")\n",
    "c[\"json\"][\"3\"] = os.path.join(c[\"dir\"][\"sample\"], \"3.json\")\n",
    "c[\"json\"][\"4.0\"] = os.path.join(c[\"dir\"][\"sample\"], \"4.0.json\")\n",
    "c[\"json\"][\"4.25\"] = os.path.join(c[\"dir\"][\"sample\"], \"4.25.json\")\n",
    "c[\"json\"][\"4.5\"] = os.path.join(c[\"dir\"][\"sample\"], \"4.5.json\")\n",
    "c[\"json\"][\"5\"] = os.path.join(c[\"dir\"][\"sample\"], \"5.json\")\n",
    "c[\"json\"][\"7\"] = os.path.join(c[\"dir\"][\"sample\"], \"7.json\")\n",
    "c[\"json\"][\"8\"] = os.path.join(c[\"dir\"][\"sample\"], \"8.json\")\n",
    "c[\"json\"][\"8.5\"] = os.path.join(c[\"dir\"][\"sample\"], \"8.5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate the md5 for the original rsem_genes.results file\n",
    "# NOTE: only works because this is a line-based file; typically should md5 in binary mode\n",
    "sample_md5 = hashlib.md5()\n",
    "# TODO - capture error on file nonexistence and fail analysis\n",
    "with open(c[\"file\"][\"rsem_genes.results\"], \"r\") as f:\n",
    "    for line in f:\n",
    "        sample_md5.update(line)\n",
    "c[\"info\"][\"rsem_genes.results_md5\"] = sample_md5.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Protocol version info : log and add to conf\n",
    "# If /app isn't a git dir, see if we have an existing conf item with the git dir\n",
    "# If we can't do that either (running manually from scratch?), mark as unknown.\n",
    "# NOTE TODO: This is hardcoded to check /app ; it will be inaccurate if not running\n",
    "# from inside docker. Not sure of best way to find \"canonical\" git dir for a run.\n",
    "\n",
    "in_git_dir=!git -C /app rev-parse --is-inside-work-tree\n",
    "if in_git_dir.n == \"true\":\n",
    "    git_hash = !git -C /app rev-parse HEAD\n",
    "    git_hash = git_hash.n\n",
    "    git_base_url = !git -C /app config --get remote.origin.url\n",
    "    git_base_url = git_base_url.n\n",
    "    if git_base_url.endswith('.git'):\n",
    "        git_base_url = git_base_url[:-4]\n",
    "    git_tag = !git -C /app describe --tags\n",
    "    git_url = \"{}/tree/{}\".format(git_base_url, git_tag.n)\n",
    "else:\n",
    "    try:\n",
    "        git_hash=\"CUSTOM; modified from {}\".format(c[\"info\"][\"git_hash\"])\n",
    "        git_url=c[\"info\"][\"git_url\"]\n",
    "    except KeyError:\n",
    "        git_hash=\"CUSTOM\"\n",
    "        git_url=\"https://github.com/UCSC-Treehouse/protocol\"\n",
    "    \n",
    "logging.info(\"Protocol git hash: {}\".format(git_hash))\n",
    "logging.info(\"This version: {}\".format(git_url))\n",
    "\n",
    "c[\"info\"][\"git_hash\"] = git_hash\n",
    "c[\"info\"][\"git_url\"] = git_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Secondary quality-control results\n",
    "# JSON file as generated / copied by run.py. Keys are:\n",
    "# input uniqMappedNonDupeReadCount estExonicUniqMappedNonDupeReadCount qc\n",
    "\n",
    "try:\n",
    "    with open(\"bam_umend_qc.json\", \"r\") as f:\n",
    "        c[\"info\"][\"secondary_qc\"] = json.load(f)\n",
    "except IOError:\n",
    "    c[\"info\"][\"secondary_qc\"] = {}        \n",
    "        \n",
    "print(c[\"info\"][\"secondary_qc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Logging: cohort version info\n",
    "logging.info(\"Outlier compendium: {}\".format(c[\"cohort\"][\"info\"][\"name\"] ))\n",
    "logging.info(\"Tumormap background cohort: {}\".format(c[\"tumormap\"][\"info\"][\"name\"] ))\n",
    "\n",
    "\n",
    "logging.info(\"rsem_genes.results md5sum: {}\".format(c[\"info\"][\"rsem_genes.results_md5\"]))\n",
    "logging.info(\"Tumormap compendium md5sum (may be same as outlier): {}\".format(c[\"tumormap\"][\"info\"][\"expression_md5\"]))\n",
    "logging.info(\"Outlier analysis compendium (cohort.hd5) md5sum: {}\".format(c[\"cohort\"][\"info\"][\"expression_md5\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Print the conf\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write the conf file\n",
    "# store it in both the sampledir and the PWD \n",
    "# (so that we can find it without needing the conf file...)\n",
    "\n",
    "with open(c[\"file\"][\"conf\"], \"w\") as conf:\n",
    "    json.dump(c, conf, indent=2)\n",
    "\n",
    "print(\"Wrote json conf to {}\".format(c[\"file\"][\"conf\"]))\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
